{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.architectures import RNNEncoder, RNNDecoder\n",
    "from src.embeddings import BasicEmbedding\n",
    "from src.initial_states import ZerosState, TrainableState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = BasicEmbedding(num_labels=5, embedding_size=6)\n",
    "embedding.eval()\n",
    "\n",
    "# X must be: [batch_size, seq_len]\n",
    "X = torch.randint(low=0, high=4, size=(2, 4), dtype=torch.long)\n",
    "output = embedding(X)\n",
    "# output shape: [batch_size, seq_len, num_features=embedding_size]\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing RNNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "embedding_size = 7\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "enc_embedding = BasicEmbedding(num_labels=5, embedding_size=embedding_size)\n",
    "\n",
    "encoder = RNNEncoder(cell=cell, embedding=enc_embedding, embedding_size=embedding_size, hidden_size=hidden_size,\n",
    "                    num_layers=num_layers, dropout=0)\n",
    "encoder.eval()\n",
    "\n",
    "# X must be: [batch_size, seq_len]\n",
    "X = torch.randint(low=0, high=4, size=(2, 4), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "# output shape: [seq_len, batch_size, hidden_size]\n",
    "# state shape: [num_layers, batch_size, hidden_size]\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Initial States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "batch_size = 2\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "init_state = ZerosState(cell, batch_size, hidden_size, num_layers)\n",
    "state = init_state()\n",
    "# state shape [num_layers, batch_size, hidden_size]\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "batch_size = 2\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "init_state = TrainableState(cell, batch_size, hidden_size, num_layers)\n",
    "state = init_state()\n",
    "# state shape [num_layers, batch_size, hidden_size]\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing RNNDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([1, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "embedding_size = 7\n",
    "input_size = embedding_size * 3\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "\n",
    "assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "variable_emb = BasicEmbedding(num_labels=5, embedding_size=embedding_size)\n",
    "\n",
    "decoder  = RNNDecoder(input_size=input_size, cell=cell, assignment_emb=assignment_emb, variable_emb=variable_emb,\n",
    "                        hidden_size=hidden_size, num_layers=num_layers)\n",
    "decoder.eval()\n",
    "\n",
    "# var must be: [batch_size, seq_len]\n",
    "var = torch.randint(0, 4, [batch_size, seq_len])\n",
    "\n",
    "# a_prev must be: [batch_size, seq_len]\n",
    "a_prev = torch.randint(0, 2, [batch_size, seq_len])\n",
    "\n",
    "# context must be: [batch_size, feature_size]\n",
    "context = torch.rand([batch_size, embedding_size])\n",
    "\n",
    "# state must be: [num_layers, batch_size, hidden_size]\n",
    "state = torch.rand([num_layers, batch_size, hidden_size])\n",
    "\n",
    "X = (var, a_prev, context)\n",
    "output, state = decoder(X, state)\n",
    "# output shape: [batch_size, seq_len, 2]\n",
    "# state shape: [num_layers, batch_size, hidden_size]\n",
    "print(output.shape)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = 'GRU'\n",
    "embedding_size = 7\n",
    "input_size = embedding_size * 3\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "\n",
    "assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "variable_emb = BasicEmbedding(num_labels=5, embedding_size=embedding_size)\n",
    "\n",
    "decoder  = RNNDecoder(input_size=input_size, cell=cell, assignment_emb=assignment_emb, variable_emb=variable_emb,\n",
    "                        hidden_size=hidden_size, num_layers=num_layers)\n",
    "decoder.eval()\n",
    "\n",
    "# var must be: [batch_size, seq_len]\n",
    "var = torch.randint(0, 4, [batch_size, seq_len])\n",
    "\n",
    "# a_prev must be: [batch_size, seq_len]\n",
    "a_prev = torch.randint(0, 2, [batch_size, seq_len])\n",
    "\n",
    "# context must be: [batch_size, feature_size]\n",
    "context = torch.rand([batch_size, embedding_size])\n",
    "\n",
    "# state must be: [num_layers, batch_size, hidden_size]\n",
    "state = torch.rand([num_layers, batch_size, hidden_size])\n",
    "\n",
    "X = (var, a_prev, context)\n",
    "output, state = decoder(X, state)\n",
    "# output shape: [batch_size, seq_len, 2]\n",
    "# state shape: [num_layers, batch_size, hidden_size]\n",
    "print(output.shape)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = torch.zeros([4, 2, 3])\n",
    "# var shape: [seq_len, batch_size, features_size=var_embedding_size]\n",
    "\n",
    "a_prev = torch.ones([4, 2, 3])\n",
    "# var shape: [seq_len, batch_size, features_size=var_embedding_size]\n",
    "        \n",
    "\n",
    "# context must be: [batch_size, feature_size]\n",
    "context = torch.rand([2, 0])\n",
    "# Broadcasting context\n",
    "context = context.repeat(var.shape[0], 1, 1)\n",
    "# context shape: [seq_len, batch_size, features_size]\n",
    "\n",
    "dec_input = torch.cat((var, a_prev, context), -1)\n",
    "# dec_input shape: [seq_len, batch_size, features_size=input_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class1():\n",
    "    def __init__(self, var1, var2, **kwargs):\n",
    "        self.var1= var1\n",
    "        self.var2 = var2\n",
    "\n",
    "    def method(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Class2(Class1):\n",
    "    def __init__(self, var1, var2, var3, **kwargs):\n",
    "        super().__init__(var1, var2, **kwargs)\n",
    "        self.var3= var3\n",
    "\n",
    "\n",
    "    def method(self):\n",
    "        print(self.var1)\n",
    "        print(self.var2)\n",
    "        print(self.var3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([], size=(2, 0))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 3\n",
    "emb_size = 4\n",
    "var = torch.zeros([batch_size, seq_len, emb_size]).permute(1,0,2)\n",
    "context = torch.empty([batch_size, 0])\n",
    "\n",
    "print(var)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(3, 2, 0))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = context.repeat(var.shape[0], 1, 1)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((var, context), -1)\n",
    "#3,2,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_prev = torch.tensor(2).reshape(1,1)\n",
    "action_prev.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_X = torch.unsqueeze(torch.tensor([2], dtype=torch.long), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2] * 5, dtype=torch.long).reshape(-1,1).shape\n",
    "# ::action_prev:: [batch_size=1, seq_len=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([i for i in range(5)]).reshape(1,-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5221, 0.4866, 0.6199, 0.5961, 0.7663],\n",
       "         [0.2851, 0.2966, 0.9776, 0.7473, 0.8604],\n",
       "         [0.2733, 0.1481, 0.4454, 0.6126, 0.7616]],\n",
       "\n",
       "        [[0.4640, 0.7413, 0.3950, 0.3177, 0.7367],\n",
       "         [0.9951, 0.9485, 0.0726, 0.0920, 0.8593],\n",
       "         [0.8353, 0.4101, 0.1689, 0.0460, 0.5975]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand([2,3,5])\n",
    "# ::var:: [batch_size, seq_len, feature_size]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:,2:3,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2def132e6ff2d4a8f828400b7561c2d8eeec08ca69bfb84d2ccf8d1757b29253"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
