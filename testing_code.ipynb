{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.init_states import BaseState, ZerosState, TrainableState\n",
    "from src.init_vars import BaseVar, BasicVar\n",
    "from src.init_contexts import BaseContext, EmptyContext\n",
    "from src.embeddings import BaseEmbedding, BasicEmbedding, IdentityEmbedding\n",
    "\n",
    "from src.encoders import RNNEncoder\n",
    "from src.decoders import RNNDecoder\n",
    "from src.encoder_decoder import EncoderDecoder\n",
    "from src.baselines import BaselineRollout\n",
    "\n",
    "from src.train import train\n",
    "from src.generator import UniformGenerator\n",
    "import src.utils as utils\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state = BaseState()\n",
    "state = init_state()\n",
    "# Expected return: NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZerosState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "enc_output = None\n",
    "batch_size = None\n",
    "\n",
    "init_state = ZerosState()\n",
    "state = init_state(enc_output, batch_size)\n",
    "# ::state:: [num_layers, batch_size, hidden_size]\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainableState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3814,  0.2384, -0.7665,  0.3343],\n",
       "         [ 0.3814,  0.2384, -0.7665,  0.3343]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "enc_output = None\n",
    "batch_size = 2\n",
    "\n",
    "init_state = TrainableState(cell, hidden_size, num_layers, a=-0.8, b=0.8)\n",
    "state = init_state(enc_output, batch_size)\n",
    "# ::state:: [num_layers, batch_size, hidden_size]\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = None\n",
    "formula = None\n",
    "num_variables = None\n",
    "variables = None\n",
    "\n",
    "init_dec_var = BaseVar()\n",
    "var = init_dec_var(enc_output, formula, num_variables, variables)\n",
    "# Expected return: NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BasicVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output = None\n",
    "formula = None\n",
    "num_variables = 5\n",
    "variables =None\n",
    "\n",
    "init_dec_var = BasicVar()\n",
    "var = init_dec_var(enc_output, formula, num_variables, variables)\n",
    "# ::var:: [batch_size=1, seq_len=num_variables, feature_size=1]\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output = None\n",
    "formula = None\n",
    "num_variables = None\n",
    "variables = None\n",
    "batch_size = None\n",
    "\n",
    "init_dec_context = BaseContext()\n",
    "context = init_dec_context(enc_output, formula, num_variables, variables, batch_size)\n",
    "# Expected return: NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmptyContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output = None\n",
    "formula = None\n",
    "num_variables = 5\n",
    "variables = None\n",
    "batch_size = 2\n",
    "\n",
    "init_dec_context = EmptyContext()\n",
    "context = init_dec_context(enc_output, formula, num_variables, variables, batch_size)\n",
    "# ::context:: [batch_size, feature_size=0]\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaseEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "feature_size = 5\n",
    "X = torch.rand((batch_size, seq_len, feature_size))\n",
    "# ::X:: [batch_size, seq_len, features_size]\n",
    "\n",
    "embedding = BaseEmbedding()\n",
    "X = embedding(X)\n",
    "# Expected return: NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BasicEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 5\n",
    "embedding_size = 10\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "X = torch.randint(low=0, high=num_labels-1, size=(batch_size, seq_len, 1), dtype=torch.long)\n",
    "# ::X:: [batch_size, seq_len, features_size=1]\n",
    "\n",
    "embedding = BasicEmbedding(num_labels, embedding_size)\n",
    "X = embedding(X)\n",
    "# ::X:: [batch_size, seq_len, num_features=embedding_size]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IdentityEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "feature_size = 5\n",
    "X = torch.rand((batch_size, seq_len, feature_size))\n",
    "# ::X:: [batch_size, seq_len, features_size]\n",
    "\n",
    "embedding = IdentityEmbedding()\n",
    "X = embedding(X)\n",
    "# ::X:: [batch_size, seq_len, features_size]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "embedding_size = 7\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "\n",
    "enc_embedding = IdentityEmbedding()\n",
    "X = torch.rand((2, 5, embedding_size))\n",
    "# ::X:: [batch_size, seq_len, features_size=embedding_size]\n",
    "\n",
    "encoder = RNNEncoder(cell = cell,\n",
    "                     embedding = enc_embedding,\n",
    "                     embedding_size = embedding_size,\n",
    "                     hidden_size = hidden_size,\n",
    "                     num_layers = num_layers,\n",
    "                     dropout = 0)\n",
    "encoder.eval()\n",
    "output, state = encoder(X)\n",
    "# ::output:: [seq_len, batch_size, hidden_size]\n",
    "# ::state:: [num_layers, batch_size, hidden_size]\n",
    "print(output.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([1, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "cell = 'GRU'\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "dropout = 0\n",
    "clip_logits_c = 0\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "embedding_size = 8\n",
    "assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "variable_emb = BasicEmbedding(num_labels=5, embedding_size=embedding_size)\n",
    "input_size = embedding_size * 3\n",
    "\n",
    "var = torch.randint(0, 4, [batch_size, seq_len, 1])\n",
    "# ::var:: [batch_size, seq_len, feature_size]\n",
    "a_prev = torch.randint(0, 2, [batch_size, seq_len, 1])\n",
    "# ::a_prev:: [batch_size, seq_len, feaure_size=1]\n",
    "context = torch.rand([batch_size, embedding_size])\n",
    "# ::context:: [batch_size, feature_size]\n",
    "state = torch.rand([num_layers, batch_size, hidden_size])\n",
    "# ::state:: [num_layers, batch_size, hidden_size]\n",
    "X = (var, a_prev, context)\n",
    "\n",
    "decoder  = RNNDecoder(input_size = input_size,\n",
    "                      cell = cell,\n",
    "                      assignment_emb = assignment_emb,\n",
    "                      variable_emb = variable_emb,\n",
    "                      hidden_size = hidden_size,\n",
    "                      num_layers = num_layers,\n",
    "                      dropout = 0,\n",
    "                      clip_logits_c = 0)\n",
    "decoder.eval()\n",
    "output, state = decoder(X, state)\n",
    "# ::output:: [batch_size, seq_len, 2]\n",
    "# ::state:: [num_layers, batch_size, hidden_size]\n",
    "print(output.shape)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.assignment_embedding.embedding.weight torch.Size([8, 3])\n",
      "decoder.assignment_embedding.embedding.bias torch.Size([8])\n",
      "decoder.variable_embedding.embedding.weight torch.Size([8, 5])\n",
      "decoder.variable_embedding.embedding.bias torch.Size([8])\n",
      "decoder.rnn.weight_ih_l0 torch.Size([48, 16])\n",
      "decoder.rnn.weight_hh_l0 torch.Size([48, 16])\n",
      "decoder.rnn.bias_ih_l0 torch.Size([48])\n",
      "decoder.rnn.bias_hh_l0 torch.Size([48])\n",
      "decoder.dense_out.weight torch.Size([2, 16])\n",
      "decoder.dense_out.bias torch.Size([2])\n",
      "init_dec_state.h torch.Size([1, 1, 16])\n"
     ]
    }
   ],
   "source": [
    "num_variables = 5\n",
    "variables = None\n",
    "\n",
    "cell = 'GRU'\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "dropout = 0\n",
    "clip_logits_c = 0\n",
    "\n",
    "embedding_size = 8\n",
    "assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "variable_emb = BasicEmbedding(num_labels=num_variables, embedding_size=embedding_size)\n",
    "input_size = embedding_size * 2\n",
    "\n",
    "init_dec_state = TrainableState(cell, hidden_size, num_layers, a=-0.8, b=0.8)\n",
    "\n",
    "encoder = None\n",
    "decoder = RNNDecoder(input_size = input_size,\n",
    "                     cell = cell,\n",
    "                     assignment_emb = assignment_emb,\n",
    "                     variable_emb = variable_emb,\n",
    "                     hidden_size = hidden_size,\n",
    "                     num_layers = num_layers,\n",
    "                     dropout = dropout,\n",
    "                     clip_logits_c = clip_logits_c)\n",
    "\n",
    "policy_network = EncoderDecoder(encoder=encoder,\n",
    "                                decoder=decoder,\n",
    "                                init_dec_var=None,\n",
    "                                init_dec_context=None,\n",
    "                                init_dec_state=init_dec_state)\n",
    "\n",
    "utils.params_summary(policy_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 5\n",
      "r: 4.2\n",
      "m: 21\n",
      "[[-5, -2, -3], [-3, -4, -1], [-3, -4, 1], [-5, -2, 4], [4, -3, 5], [-5, -2, -1], [-4, -1, -2], [-4, -5, -1], [-3, -5, -1], [-3, 1, -5], [1, 3, 4], [4, 3, 5], [2, 1, 3], [-2, -3, -5], [5, -1, 4], [1, -4, -5], [-4, -3, 2], [-2, -1, 5], [3, -2, 4], [-4, -1, -5], [-4, 2, 5]]\n"
     ]
    }
   ],
   "source": [
    "#Create a sat generator\n",
    "sat_gen = UniformGenerator(min_n = 5,\n",
    "                           max_n = 5,\n",
    "                           min_k = 3,\n",
    "                           max_k = 3,\n",
    "                           min_r = 4.2,\n",
    "                           max_r = 4.2)\n",
    "\n",
    "#Create a random sat formula\n",
    "n, r, m, formula = sat_gen.generate_formula()\n",
    "\n",
    "print(f'n: {n}')\n",
    "print(f'r: {r}')\n",
    "print(f'm: {m}')\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [1/10], Mean Loss 59.7945,  Mean num sat 19.0000\n",
      "Episode [2/10], Mean Loss 80.7731,  Mean num sat 19.0000\n",
      "Episode [3/10], Mean Loss 44.6474,  Mean num sat 18.0000\n",
      "Episode [4/10], Mean Loss 75.6491,  Mean num sat 18.0000\n",
      "Episode [5/10], Mean Loss 62.8202,  Mean num sat 18.0000\n",
      "Episode [6/10], Mean Loss 70.7435,  Mean num sat 20.0000\n",
      "Episode [7/10], Mean Loss 50.4938,  Mean num sat 18.0000\n",
      "Episode [8/10], Mean Loss 63.2537,  Mean num sat 17.0000\n",
      "Episode [9/10], Mean Loss 61.8325,  Mean num sat 18.0000\n",
      "Episode [10/10], Mean Loss 50.0508,  Mean num sat 18.0000\n"
     ]
    }
   ],
   "source": [
    "formula = formula\n",
    "num_variables = 5\n",
    "variables = None\n",
    "num_episodes = 10\n",
    "accumulation_steps = 1\n",
    "\n",
    "cell = 'GRU'\n",
    "hidden_size = 16\n",
    "num_layers = 1\n",
    "dropout = 0\n",
    "clip_logits_c = 0\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "embedding_size = 8\n",
    "assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "variable_emb = BasicEmbedding(num_labels=num_variables, embedding_size=embedding_size)\n",
    "input_size = embedding_size * 2\n",
    "\n",
    "encoder = None\n",
    "decoder = RNNDecoder(input_size = input_size,\n",
    "                     cell = cell,\n",
    "                     assignment_emb = assignment_emb,\n",
    "                     variable_emb = variable_emb,\n",
    "                     hidden_size = hidden_size,\n",
    "                     num_layers = num_layers,\n",
    "                     dropout = dropout,\n",
    "                     clip_logits_c = clip_logits_c)\n",
    "init_dec_state = TrainableState(cell, hidden_size, num_layers)\n",
    "\n",
    "policy_network = EncoderDecoder(encoder=encoder,\n",
    "                                decoder=decoder,\n",
    "                                init_dec_var=None,\n",
    "                                init_dec_context=None,\n",
    "                                init_dec_state=init_dec_state)\n",
    "\n",
    "optimizer = optim.Adam(policy_network.parameters(), lr=lr)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "baseline = None #BaselineRollout(-1)  # None\n",
    "entropy_weight = 0\n",
    "clip_val = 1\n",
    "verbose = 2\n",
    "\n",
    "history_loss, history_num_sat = train(formula,\n",
    "                                    num_variables,\n",
    "                                    variables,\n",
    "                                    num_episodes,\n",
    "                                    accumulation_steps,\n",
    "                                    policy_network,\n",
    "                                    optimizer,\n",
    "                                    device,\n",
    "                                    baseline,\n",
    "                                    entropy_weight,\n",
    "                                    clip_val,\n",
    "                                    verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2def132e6ff2d4a8f828400b7561c2d8eeec08ca69bfb84d2ccf8d1757b29253"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
