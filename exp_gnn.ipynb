{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "\n",
    "1. Create a random sat formula\n",
    "* n = 10\n",
    "* k = 3\n",
    "* r = 4.0, 4.2, 4.4, 4.6\n",
    "\n",
    "\n",
    "1. Check the number of sat clauses with the following solvers (mean over 10 times)\n",
    "* Learning solver with greedy baseline trainable initial state\n",
    "* Learning solver with greedy baseline and zeros initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.encoders import GCNEncoder\n",
    "from src.decoders import RNNDecoder\n",
    "from src.encoder_decoder import EncoderDecoder\n",
    "from src.embeddings import BasicEmbedding, IdentityEmbedding\n",
    "from src.baselines import BaselineRollout\n",
    "from src.init_states import EncoderOutputState\n",
    "from src.init_vars import IdentityEncoderOutputVar\n",
    "from src.init_contexts import EncoderOutputContext\n",
    "\n",
    "from src.generator import UniformGenerator\n",
    "from src.run_solvers import random_solver, learning_solver\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import tensorboard as tb\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_zstate(formula, baseline):\n",
    "    # Architecture\n",
    "    cell = 'GRU'\n",
    "    hidden_size = 128\n",
    "    num_layers = 1\n",
    "    dropout = 0\n",
    "    clip_logits_c = 0 #(default: 0)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    ## Embeddings\n",
    "    embedding_size = 32\n",
    "    assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "    variable_emb = IdentityEmbedding()\n",
    "    context_emb = IdentityEmbedding()\n",
    "    input_size = embedding_size * 3\n",
    "\n",
    "    # Encoder\n",
    "    encoder = GCNEncoder(\n",
    "        embedding_size=embedding_size,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    decoder = RNNDecoder(input_size = input_size,\n",
    "                        cell = cell,\n",
    "                        assignment_emb = assignment_emb,\n",
    "                        variable_emb = variable_emb,\n",
    "                        context_emb = context_emb,\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_layers = num_layers,\n",
    "                        dropout = dropout,\n",
    "                        clip_logits_c = clip_logits_c)\n",
    "    ## Initializers\n",
    "    init_dec_var = IdentityEncoderOutputVar()\n",
    "    init_dec_context = EncoderOutputContext(aggregation=\"max\")\n",
    "    init_dec_state = EncoderOutputState(embedding_size, hidden_size, aggregation=\"mean\")\n",
    "\n",
    "    ## Network\n",
    "    policy_network = EncoderDecoder(encoder=encoder,\n",
    "                                    decoder=decoder,\n",
    "                                    init_dec_var=init_dec_var,\n",
    "                                    init_dec_context=init_dec_context,\n",
    "                                    init_dec_state=init_dec_state)\n",
    "\n",
    "    # Training hyperparameters\n",
    "    num_episodes = 500\n",
    "    accumulation_steps = 1\n",
    "    lr = 1e-3\n",
    "    #baseline = \n",
    "    entropy_weight = 0\n",
    "    clip_val = 1\n",
    "    verbose = 1\n",
    "\n",
    "    variables = None\n",
    "\n",
    "    # num_sat, history_loss, history_num_sat\n",
    "    return learning_solver(formula=formula,\n",
    "                        num_variables=num_variables,\n",
    "                        variables=variables,\n",
    "                        encoder=encoder,\n",
    "                        decoder=decoder,\n",
    "                        init_dec_var=init_dec_var,\n",
    "                        init_dec_context=init_dec_context,\n",
    "                        init_dec_state=init_dec_state, \n",
    "                        num_episodes=num_episodes,\n",
    "                        accumulation_steps=accumulation_steps,\n",
    "                        lr=lr,\n",
    "                        device=device,\n",
    "                        baseline=baseline,\n",
    "                        entropy_weight=entropy_weight,\n",
    "                        clip_val=clip_val,\n",
    "                        verbose=verbose)\n",
    "\n",
    "\n",
    "def run_model_tstate(formula, baseline):\n",
    "    # Architecture\n",
    "    cell = 'GRU'\n",
    "    hidden_size = 128\n",
    "    num_layers = 1\n",
    "    dropout = 0\n",
    "    clip_logits_c = 0 #(default: 0)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    ## Embeddings\n",
    "    embedding_size = 32\n",
    "    assignment_emb = BasicEmbedding(num_labels=3, embedding_size=embedding_size)\n",
    "    variable_emb = IdentityEmbedding()\n",
    "    context_emb = IdentityEmbedding()\n",
    "    input_size = embedding_size * 3\n",
    "\n",
    "    # Encoder\n",
    "    encoder = GCNEncoder(\n",
    "        embedding_size=embedding_size,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    decoder = RNNDecoder(input_size = input_size,\n",
    "                        cell = cell,\n",
    "                        assignment_emb = assignment_emb,\n",
    "                        variable_emb = variable_emb,\n",
    "                        context_emb = context_emb,\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_layers = num_layers,\n",
    "                        dropout = dropout,\n",
    "                        clip_logits_c = clip_logits_c)\n",
    "    ## Initializers\n",
    "    init_dec_var = IdentityEncoderOutputVar()\n",
    "    init_dec_context = EncoderOutputContext(aggregation=\"max\")\n",
    "    init_dec_state = EncoderOutputState(embedding_size, hidden_size, aggregation=\"mean\")\n",
    "\n",
    "    ## Network\n",
    "    policy_network = EncoderDecoder(encoder=encoder,\n",
    "                                    decoder=decoder,\n",
    "                                    init_dec_var=init_dec_var,\n",
    "                                    init_dec_context=init_dec_context,\n",
    "                                    init_dec_state=init_dec_state)\n",
    "\n",
    "    # Training hyperparameters\n",
    "    num_episodes = 500\n",
    "    accumulation_steps = 1\n",
    "    lr = 1e-3\n",
    "    #baseline = \n",
    "    entropy_weight = 0\n",
    "    clip_val = 1\n",
    "    verbose = 1\n",
    "\n",
    "    variables = None\n",
    "\n",
    "    # num_sat, history_loss, history_num_sat\n",
    "    return learning_solver(formula=formula,\n",
    "                        num_variables=num_variables,\n",
    "                        variables=variables,\n",
    "                        encoder=encoder,\n",
    "                        decoder=decoder,\n",
    "                        init_dec_var=init_dec_var,\n",
    "                        init_dec_context=init_dec_context,\n",
    "                        init_dec_state=init_dec_state, \n",
    "                        num_episodes=num_episodes,\n",
    "                        accumulation_steps=accumulation_steps,\n",
    "                        lr=lr,\n",
    "                        device=device,\n",
    "                        baseline=baseline,\n",
    "                        entropy_weight=entropy_weight,\n",
    "                        clip_val=clip_val,\n",
    "                        verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 4.0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:05<09:51, 65.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n",
      "Episode [500/500], Mean Loss 3.5534,  Mean num sat 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:08<08:30, 63.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 71.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:09<07:18, 62.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 73.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:10<06:12, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 73.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 67.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:12<05:10, 62.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 69.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 72.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:15<04:08, 62.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 72.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 72.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:15<03:05, 61.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 72.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 78.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [08:17<02:03, 61.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 79.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:18<01:01, 61.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 73.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:19<00:00, 61.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 73.0000\n",
      "r = 4.2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 76.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:01<09:12, 61.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 76.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:04<08:19, 62.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 80.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:06<07:16, 62.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 79.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:07<06:11, 61.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 79.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:14<05:17, 63.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:18<04:15, 63.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 75.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 79.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:24<03:13, 64.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 81.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [08:30<02:10, 65.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 81.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 74.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:35<01:04, 64.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 82.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:39<00:00, 63.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 77.0000\n",
      "r = 4.4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 83.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:03<09:34, 63.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 83.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 78.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:07<08:29, 63.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss -5.0951,  Mean num sat 77.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 85.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:11<07:27, 63.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 4.3698,  Mean num sat 84.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 80.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [04:17<06:27, 64.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 80.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 81.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [05:21<05:22, 64.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 81.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 88.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [06:24<04:16, 64.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 80.0000\n",
      "Episode [500/500], Mean Loss 10.8708,  Mean num sat 86.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [07:28<03:11, 63.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 79.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 82.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [08:32<02:07, 63.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 78.0000\n",
      "Episode [500/500], Mean Loss -20.4273,  Mean num sat 82.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [09:36<01:03, 63.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 81.0000\n",
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 78.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [10:40<00:00, 64.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode [500/500], Mean Loss 0.0000,  Mean num sat 78.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'expgnn'\n",
    "num_experiments = 10 #num of times each experiment is run\n",
    "\n",
    "# CNF Formula\n",
    "num_variables = 20  # Num variables\n",
    "k = 3   # Clause size\n",
    "r_list = [4.0, 4.2, 4.4] #Radious\n",
    "\n",
    "global_step = 0\n",
    "for _, r in enumerate(r_list):\n",
    "    print(f'r = {r} ...')\n",
    "\n",
    "    log_dir='outputs/' + experiment_name + '/runs/n' + str(num_variables) +'/'+str(r)\n",
    "    writer = SummaryWriter(log_dir = log_dir)        \n",
    "\n",
    "    # Create a sat generator\n",
    "    sat_gen = UniformGenerator(min_n = num_variables,\n",
    "                                max_n = num_variables,\n",
    "                                min_k = k,\n",
    "                                max_k = k,\n",
    "                                min_r = r,\n",
    "                                max_r = r)\n",
    "    \n",
    "    for _ in tqdm(range(num_experiments)):\n",
    "            \n",
    "        # Create a random sat formula\n",
    "        n, r, m, formula = sat_gen.generate_formula()\n",
    "\n",
    "        ##################################################################\n",
    "        # Random solver                                                  #\n",
    "        ##################################################################\n",
    "        num_sat = random_solver(n, formula)\n",
    "        writer.add_scalar('random', num_sat, global_step, new_style=True)\n",
    "\n",
    "\n",
    "        ##################################################################\n",
    "        # Learning model with 1-sampled basleine                         #\n",
    "        ##################################################################\n",
    "        baseline = BaselineRollout(1)\n",
    "        num_sat, _,_ = run_model_zstate(formula, baseline)\n",
    "        writer.add_scalar('learned_gb_zstate', num_sat, global_step, new_style=True)\n",
    "\n",
    "        ##################################################################\n",
    "        # Learning model with 2-sampled basleine                         #\n",
    "        ##################################################################\n",
    "        baseline = BaselineRollout(2)\n",
    "        num_sat, _,_ = run_model_tstate(formula, baseline)\n",
    "        writer.add_scalar('learning_gb_tstate', num_sat, global_step, new_style=True)\n",
    "\n",
    "        global_step +=1\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "_MultiThreadedRendezvous",
     "evalue": "<_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Internal error. Please report this and specify reference code 4a5be3ee-cfcf-4233-83d7-e17718152738.\"\n\tdebug_error_string = \"{\"created\":\"@1651464479.742563768\",\"description\":\"Error received from peer ipv4:34.95.66.171:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":903,\"grpc_message\":\"Internal error. Please report this and specify reference code 4a5be3ee-cfcf-4233-83d7-e17718152738.\",\"grpc_status\":13}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16349/365353004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexperiment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'22ZkNiaJTKKaMhOztOWzoA/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExperimentFromDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/DCC-tsp/lib/python3.9/site-packages/tensorboard/data/experimental/experiment_from_dev.py\u001b[0m in \u001b[0;36mget_scalars\u001b[0;34m(self, runs_filter, tags_filter, pivot, include_wall_time)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mwall_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;31m# TODO(cais, wchargin): Display progress bar during data loading.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mnum_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/DCC-tsp/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Miniconda3/envs/DCC-tsp/lib/python3.9/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"Internal error. Please report this and specify reference code 4a5be3ee-cfcf-4233-83d7-e17718152738.\"\n\tdebug_error_string = \"{\"created\":\"@1651464479.742563768\",\"description\":\"Error received from peer ipv4:34.95.66.171:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":903,\"grpc_message\":\"Internal error. Please report this and specify reference code 4a5be3ee-cfcf-4233-83d7-e17718152738.\",\"grpc_status\":13}\"\n>"
     ]
    }
   ],
   "source": [
    "#Upload log_dir\n",
    "#tensorboard dev upload --logdir 'outputs/exp0/runs/n20'\n",
    "\n",
    "#from tensorboard experimental to dataframe\n",
    "#https://tensorboard.dev/experiment/nGoxU6HWQMaduPCXvBpxgw/\n",
    "experiment_id = '22ZkNiaJTKKaMhOztOWzoA/'\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df = experiment.get_scalars()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe as csv\n",
    "csv_path = 'csv/sip_expgnn.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.rename(columns = {'run': 'radius'}, inplace = False)\n",
    "\n",
    "df2['ratio'] = df2['value'] * 1/(df2['radius'].astype(float) * num_variables)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.lineplot(x='radius', y='ratio', hue='tag', ci=20, data=df2, estimator='mean').set_title(\"Ratio of satisfied clauses\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2def132e6ff2d4a8f828400b7561c2d8eeec08ca69bfb84d2ccf8d1757b29253"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 ('torch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
