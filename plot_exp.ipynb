{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils as utils\n",
    "from src.solvers import pg_solver\n",
    "from ray import tune\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from tbparse import SummaryReader\n",
    "import seaborn as sns; sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Load best results from hyperparameter tuning\n",
    "#exp_path = 'hypersearch2/pg_solver/0020/0020/rand_n=0020_k=03_m=0020_i=01/arch'\n",
    "exp_path = 'hypersearch/pg_solver/0010/0010/rand_n=0010_k=03_m=0010_i=01/arch'\n",
    "restored_tuner = tune.Tuner.restore(path=exp_path,\n",
    "                                    trainable=pg_solver,\n",
    "                                    resume_unfinished=False,\n",
    "                                    resume_errored=False,\n",
    "                                    restart_errored=False)\n",
    "results = restored_tuner.get_results()\n",
    "\n",
    "# Check if there have been any errors\n",
    "print(results.errors)\n",
    "print(results.num_errors)\n",
    "print(results.num_terminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors for n = 10: 0. Total searchs: 120\n"
     ]
    }
   ],
   "source": [
    "num_vars = 10\n",
    "exp_folder = 'hypersearch/pg_solver'\n",
    "\n",
    "# Get path for every hyperparameter search\n",
    "exp_folder = os.path.join(exp_folder, f'{num_vars:04d}')\n",
    "folder_clauses = sorted([os.path.join(exp_folder, folder) for folder in os.listdir(exp_folder)])\n",
    "folder_instances = sorted([os.path.join(folder, instance) for folder in folder_clauses for instance in os.listdir(folder)])\n",
    "folder_assumption = sorted([os.path.join(folder, assumption) for folder in folder_instances for assumption in os.listdir(folder)])\n",
    "\n",
    "errors = 0\n",
    "for i, search_path in enumerate(folder_assumption):\n",
    "    restored_tuner = tune.Tuner.restore(path=exp_path,\n",
    "                                    trainable=pg_solver,\n",
    "                                    resume_unfinished=False,\n",
    "                                    resume_errored=False,\n",
    "                                    restart_errored=False)\n",
    "    \n",
    "    results = restored_tuner.get_results()\n",
    "    \n",
    "    if results.num_errors > 0:\n",
    "        errors += 1\n",
    "        #print(i, results.errors, results.num_errors, results.num_terminated)\n",
    "        #print(search_path)\n",
    "        #print()\n",
    "\n",
    "print(f'Total errors for n = {num_vars}: {errors}. Total searchs: {len(folder_assumption)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why it is important to load dataframe instead of get_best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors reported.\n",
      "44.0\n",
      "43.0\n",
      "44.0\n"
     ]
    }
   ],
   "source": [
    "# Load best results\n",
    "#exp_path = 'hypersearch_31may/pg_solver/0050/0075/rand_n=0050_k=03_m=0075_i=01/baseline'\n",
    "exp_path = 'hypersearch/pg_solver/0010/0045/rand_n=0010_k=03_m=0045_i=01/arch'\n",
    "\n",
    "restored_tuner = tune.Tuner.restore(path=exp_path,\n",
    "                                    trainable=pg_solver)\n",
    "\n",
    "results = restored_tuner.get_results()\n",
    "\n",
    "# Check if there have been errors\n",
    "if results.errors:\n",
    "    print(\"Errors reported.\")\n",
    "else:\n",
    "    print(\"No errors reported.\")\n",
    "\n",
    "# Get best trial\n",
    "print(results.get_best_result(metric='num_sat_eval', mode='max', scope='last').metrics['num_sat_eval'])\n",
    "print(results.get_best_result(metric='num_sat_eval', mode='max', scope='all').metrics['num_sat_eval'])\n",
    "print(results.get_dataframe(filter_metric='num_sat_eval', filter_mode='max')['num_sat_eval'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path for every hyperparameters search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
